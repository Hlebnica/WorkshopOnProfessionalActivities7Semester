{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт данных\n",
    "test_data = pd.read_csv(\"./input/test.txt\", header=None, sep=\";\", names=[\"Comment\",\"Emotion\"], encoding=\"utf-8\")\n",
    "train_data = pd.read_csv(\"./input/train.txt\", header=None, sep=\";\", names=[\"Comment\",\"Emotion\"], encoding=\"utf-8\")\n",
    "validation_data = pd.read_csv(\"./input/val.txt\", header=None, sep=\";\", names=[\"Comment\",\"Emotion\"], encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :  (16000, 2)\n",
      "Test :  (2000, 2)\n",
      "Validation :  (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train : \", train_data.shape)\n",
    "print(\"Test : \", test_data.shape)\n",
    "print(\"Validation : \", validation_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['sadness', 'anger', 'love', 'surprise', 'fear', 'joy']\n"
     ]
    }
   ],
   "source": [
    "print(\"Class names:\",  train_data[\"Emotion\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Emotion\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование \"Emotion\" в числовой формат с использованием LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "train_data[\"Emotion\"] = lb.fit_transform(train_data[\"Emotion\"])\n",
    "test_data[\"Emotion\"] = lb.fit_transform(test_data[\"Emotion\"])\n",
    "validation_data[\"Emotion\"] = lb.fit_transform(validation_data[\"Emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Emotion\n",
       "0                            i didnt feel humiliated        4\n",
       "1  i can go from feeling so hopeless to so damned...        4\n",
       "2   im grabbing a minute to post i feel greedy wrong        0\n",
       "3  i am ever feeling nostalgic about the fireplac...        3\n",
       "4                               i am feeling grouchy        0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: [4, 0, 3, 5, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Class names:\",  train_data[\"Emotion\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n",
      "[nltk_data]     Temporary failure in name resolution>\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000 # размер словаря (количество уникальных слов при обучении)\n",
    "len_sentence = 150 # длина предложений\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english')) # стоп слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка текста\n",
    "def text_prepare(data, column):\n",
    "    print(data.shape)\n",
    "    stemmer = PorterStemmer()\n",
    "    corpus = []\n",
    "    \n",
    "    for text in data[column]:\n",
    "        text = re.sub(\"[^a-zA-Z]\", \" \", text) # удалить все символы, кроме букв.\n",
    "        \n",
    "        text = text.lower()\n",
    "        text = text.split()\n",
    "        \n",
    "        text = [stemmer.stem(word) for word in text if word not in stopwords] # применить стемминг (привести слово к основной форме) и удалить стоп-слова\n",
    "        text = \" \".join(text)\n",
    "        \n",
    "        corpus.append(text)\n",
    "    one_hot_word = [one_hot(input_text=word, n=vocab_size) for word in corpus] # кодирование слов в числовой формат\n",
    "    embeddec_doc = pad_sequences(sequences=one_hot_word,\n",
    "                              maxlen=len_sentence,\n",
    "                              padding=\"pre\") # обрезка последовательностей до фиксированной длины\n",
    "    print(data.shape)\n",
    "    return embeddec_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 2)\n",
      "(16000, 2)\n",
      "(2000, 2)\n",
      "(2000, 2)\n",
      "(2000, 2)\n",
      "(2000, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train = text_prepare(train_data, \"Comment\")\n",
    "x_validate = text_prepare(validation_data, \"Comment\")\n",
    "x_test = text_prepare(test_data, \"Comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_data[\"Emotion\"]\n",
    "y_validate=validation_data[\"Emotion\"]\n",
    "y_test=test_data[\"Emotion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "y_train = np.array(y_train)\n",
    "y_train = enc.fit_transform(y_train.reshape(-1,1)).toarray() # Преобразование меток классов в бинарные векторы с использованием OneHotEncoder \n",
    "                                                             # Для использования меток классов в нейронной сети\n",
    "                                                             # Каждая строка матрицы представляет класс, а каждый столбец - принадлежность к соответствующему классу \n",
    "                                                             \n",
    "y_test = np.array(y_test)\n",
    "y_validate = np.array(y_validate)\n",
    "\n",
    "y_test = enc.fit_transform(y_test.reshape(-1,1)).toarray()\n",
    "y_validate = enc.fit_transform(y_validate.reshape(-1,1)).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import Precision, Recall\n",
    "\n",
    "\n",
    "# optimizer_ = \"Adam\"\n",
    "optimizer_ = keras.optimizers.Nadam(learning_rate=0.002)\n",
    "loss_ = \"categorical_crossentropy\"\n",
    "epochs_ = 20\n",
    "batch_size_ = 32\n",
    "metrics_ = [Precision(), Recall(), \"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 150, 150)          1500000   \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 150, 150)          0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 128)               142848    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1651494 (6.30 MB)\n",
      "Trainable params: 1651494 (6.30 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Рекуррентная нейронная сеть \n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=150, input_length=len_sentence)) # Слой векторных представлений слов (используется для обработки естественного языка (классификации текста))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128)) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizer_, loss = loss_, metrics=metrics_)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "500/500 [==============================] - 18s 33ms/step - loss: 1.1299 - precision_3: 0.8357 - recall_3: 0.3812 - accuracy: 0.5748 - val_loss: 0.4579 - val_precision_3: 0.8773 - val_recall_3: 0.8190 - val_accuracy: 0.8380\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 9s 19ms/step - loss: 0.3313 - precision_3: 0.9061 - recall_3: 0.8686 - accuracy: 0.8872 - val_loss: 0.2756 - val_precision_3: 0.9124 - val_recall_3: 0.8855 - val_accuracy: 0.8945\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 9s 18ms/step - loss: 0.2161 - precision_3: 0.9310 - recall_3: 0.9131 - accuracy: 0.9212 - val_loss: 0.3200 - val_precision_3: 0.8931 - val_recall_3: 0.8685 - val_accuracy: 0.8800\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.1609 - precision_3: 0.9450 - recall_3: 0.9348 - accuracy: 0.9399 - val_loss: 0.3112 - val_precision_3: 0.8934 - val_recall_3: 0.8760 - val_accuracy: 0.8835\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 8s 16ms/step - loss: 0.1300 - precision_3: 0.9552 - recall_3: 0.9476 - accuracy: 0.9511 - val_loss: 0.3483 - val_precision_3: 0.8915 - val_recall_3: 0.8830 - val_accuracy: 0.8875\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 8s 16ms/step - loss: 0.1028 - precision_3: 0.9668 - recall_3: 0.9607 - accuracy: 0.9635 - val_loss: 0.3561 - val_precision_3: 0.8948 - val_recall_3: 0.8850 - val_accuracy: 0.8915\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.0827 - precision_3: 0.9729 - recall_3: 0.9686 - accuracy: 0.9702 - val_loss: 0.4124 - val_precision_3: 0.8915 - val_recall_3: 0.8835 - val_accuracy: 0.8860\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.0733 - precision_3: 0.9758 - recall_3: 0.9721 - accuracy: 0.9738 - val_loss: 0.4001 - val_precision_3: 0.8949 - val_recall_3: 0.8855 - val_accuracy: 0.8890\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 8s 16ms/step - loss: 0.0586 - precision_3: 0.9794 - recall_3: 0.9766 - accuracy: 0.9773 - val_loss: 0.4405 - val_precision_3: 0.8919 - val_recall_3: 0.8825 - val_accuracy: 0.8855\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.0539 - precision_3: 0.9807 - recall_3: 0.9777 - accuracy: 0.9787 - val_loss: 0.4612 - val_precision_3: 0.8911 - val_recall_3: 0.8840 - val_accuracy: 0.8860\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.0496 - precision_3: 0.9830 - recall_3: 0.9803 - accuracy: 0.9816 - val_loss: 0.4708 - val_precision_3: 0.8846 - val_recall_3: 0.8775 - val_accuracy: 0.8815\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 0.0406 - precision_3: 0.9861 - recall_3: 0.9840 - accuracy: 0.9849 - val_loss: 0.5488 - val_precision_3: 0.8820 - val_recall_3: 0.8785 - val_accuracy: 0.8805\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 9s 17ms/step - loss: 0.0371 - precision_3: 0.9865 - recall_3: 0.9850 - accuracy: 0.9855 - val_loss: 0.5116 - val_precision_3: 0.8851 - val_recall_3: 0.8785 - val_accuracy: 0.8805\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.0396 - precision_3: 0.9868 - recall_3: 0.9852 - accuracy: 0.9859 - val_loss: 0.5248 - val_precision_3: 0.8910 - val_recall_3: 0.8870 - val_accuracy: 0.8880\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 8s 16ms/step - loss: 0.0316 - precision_3: 0.9888 - recall_3: 0.9870 - accuracy: 0.9876 - val_loss: 0.5559 - val_precision_3: 0.8875 - val_recall_3: 0.8835 - val_accuracy: 0.8850\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 8s 16ms/step - loss: 0.0303 - precision_3: 0.9900 - recall_3: 0.9887 - accuracy: 0.9894 - val_loss: 0.5402 - val_precision_3: 0.8912 - val_recall_3: 0.8890 - val_accuracy: 0.8895\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.0258 - precision_3: 0.9901 - recall_3: 0.9890 - accuracy: 0.9893 - val_loss: 0.6152 - val_precision_3: 0.8835 - val_recall_3: 0.8795 - val_accuracy: 0.8815\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.0260 - precision_3: 0.9908 - recall_3: 0.9897 - accuracy: 0.9902 - val_loss: 0.6020 - val_precision_3: 0.8844 - val_recall_3: 0.8800 - val_accuracy: 0.8820\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 8s 15ms/step - loss: 0.0238 - precision_3: 0.9920 - recall_3: 0.9908 - accuracy: 0.9912 - val_loss: 0.6361 - val_precision_3: 0.8836 - val_recall_3: 0.8805 - val_accuracy: 0.8820\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 8s 16ms/step - loss: 0.0245 - precision_3: 0.9915 - recall_3: 0.9902 - accuracy: 0.9907 - val_loss: 0.6140 - val_precision_3: 0.8870 - val_recall_3: 0.8830 - val_accuracy: 0.8845\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = epochs_, batch_size = batch_size_, validation_data=(x_validate, y_validate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
