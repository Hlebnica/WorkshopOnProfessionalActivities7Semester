{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import keras\n",
    "from keras.metrics import Precision, Recall\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт данных\n",
    "test_data = pd.read_csv(\"./input/test.txt\", header=None, sep=\";\", names=[\"Comment\",\"Emotion\"], encoding=\"utf-8\")\n",
    "train_data = pd.read_csv(\"./input/train.txt\", header=None, sep=\";\", names=[\"Comment\",\"Emotion\"], encoding=\"utf-8\")\n",
    "validation_data = pd.read_csv(\"./input/val.txt\", header=None, sep=\";\", names=[\"Comment\",\"Emotion\"], encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :  (16000, 2)\n",
      "Test :  (2000, 2)\n",
      "Validation :  (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train : \", train_data.shape)\n",
    "print(\"Test : \", test_data.shape)\n",
    "print(\"Validation : \", validation_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['sadness', 'anger', 'love', 'surprise', 'fear', 'joy']\n"
     ]
    }
   ],
   "source": [
    "print(\"Class names:\",  train_data[\"Emotion\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Emotion\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование \"Emotion\" в числовой формат с использованием LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "train_data[\"Emotion\"] = lb.fit_transform(train_data[\"Emotion\"])\n",
    "test_data[\"Emotion\"] = lb.fit_transform(test_data[\"Emotion\"])\n",
    "validation_data[\"Emotion\"] = lb.fit_transform(validation_data[\"Emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Emotion\n",
       "0                            i didnt feel humiliated        4\n",
       "1  i can go from feeling so hopeless to so damned...        4\n",
       "2   im grabbing a minute to post i feel greedy wrong        0\n",
       "3  i am ever feeling nostalgic about the fireplac...        3\n",
       "4                               i am feeling grouchy        0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: [4, 0, 3, 5, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Class names:\",  train_data[\"Emotion\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000 # размер словаря (количество уникальных слов при обучении)\n",
    "len_sentence = 150 # длина предложений\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english')) # стоп слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка текста\n",
    "def text_prepare(data, column):\n",
    "    print(data.shape)\n",
    "    stemmer = PorterStemmer()\n",
    "    corpus = []\n",
    "    \n",
    "    for text in data[column]:\n",
    "        text = re.sub(\"[^a-zA-Z]\", \" \", text) # удалить все символы, кроме букв.\n",
    "        \n",
    "        text = text.lower()\n",
    "        text = text.split()\n",
    "        \n",
    "        text = [stemmer.stem(word) for word in text if word not in stopwords] # применить стемминг (привести слово к основной форме) и удалить стоп-слова\n",
    "        text = \" \".join(text)\n",
    "        \n",
    "        corpus.append(text)\n",
    "    one_hot_word = [one_hot(input_text=word, n=vocab_size) for word in corpus] # кодирование слов в числовой формат\n",
    "    embeddec_doc = pad_sequences(sequences=one_hot_word,\n",
    "                              maxlen=len_sentence,\n",
    "                              padding=\"pre\") # обрезка последовательностей до фиксированной длины\n",
    "    print(data.shape)\n",
    "    return embeddec_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 2)\n",
      "(16000, 2)\n",
      "(2000, 2)\n",
      "(2000, 2)\n",
      "(2000, 2)\n",
      "(2000, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train = text_prepare(train_data, \"Comment\")\n",
    "x_validate = text_prepare(validation_data, \"Comment\")\n",
    "x_test = text_prepare(test_data, \"Comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_data[\"Emotion\"]\n",
    "y_validate=validation_data[\"Emotion\"]\n",
    "y_test=test_data[\"Emotion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "y_train = np.array(y_train)\n",
    "y_train = enc.fit_transform(y_train.reshape(-1,1)).toarray() # Преобразование меток классов в бинарные векторы с использованием OneHotEncoder \n",
    "                                                             # Для использования меток классов в нейронной сети\n",
    "                                                             # Каждая строка матрицы представляет класс, а каждый столбец - принадлежность к соответствующему классу \n",
    "                                                             \n",
    "y_test = np.array(y_test)\n",
    "y_validate = np.array(y_validate)\n",
    "\n",
    "y_test = enc.fit_transform(y_test.reshape(-1,1)).toarray()\n",
    "y_validate = enc.fit_transform(y_validate.reshape(-1,1)).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer_ = \"Adam\"\n",
    "optimizer_ = keras.optimizers.Nadam(learning_rate=0.002)\n",
    "loss_ = \"categorical_crossentropy\"\n",
    "epochs_ = 5\n",
    "batch_size_ = 32\n",
    "metrics_ = [Precision(), Recall(), \"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 150, 150)          1500000   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 150, 150)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               142848    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1651494 (6.30 MB)\n",
      "Trainable params: 1651494 (6.30 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Рекуррентная нейронная сеть \n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=150, input_length=len_sentence)) # Слой векторных представлений слов (используется для обработки естественного языка (классификации текста))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128)) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizer_, loss = loss_, metrics=metrics_)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 70s 136ms/step - loss: 1.2976 - precision: 0.7646 - recall: 0.2751 - accuracy: 0.5040 - val_loss: 0.6712 - val_precision: 0.8525 - val_recall: 0.7255 - val_accuracy: 0.7995\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 67s 133ms/step - loss: 0.4183 - precision: 0.8909 - recall: 0.8369 - accuracy: 0.8644 - val_loss: 0.3332 - val_precision: 0.8970 - val_recall: 0.8710 - val_accuracy: 0.8825\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 67s 134ms/step - loss: 0.2404 - precision: 0.9227 - recall: 0.9021 - accuracy: 0.9134 - val_loss: 0.2998 - val_precision: 0.9018 - val_recall: 0.8865 - val_accuracy: 0.8925\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.1698 - precision: 0.9415 - recall: 0.9302 - accuracy: 0.9360 - val_loss: 0.3335 - val_precision: 0.8892 - val_recall: 0.8790 - val_accuracy: 0.8835\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 69s 138ms/step - loss: 0.1380 - precision: 0.9539 - recall: 0.9458 - accuracy: 0.9496 - val_loss: 0.3335 - val_precision: 0.8925 - val_recall: 0.8840 - val_accuracy: 0.8885\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = epochs_, batch_size = batch_size_, validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "(2, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Text: I feel happy today, Predicted Emotion: joy\n",
      "Text: This is a sad day, Predicted Emotion: sadness\n"
     ]
    }
   ],
   "source": [
    "# Подготовка новых текстов\n",
    "new_texts = [\"I feel happy today\", \"This is a sad day\"]\n",
    "x_new = text_prepare(pd.DataFrame({\"Comment\": new_texts}), \"Comment\")\n",
    "\n",
    "# Прогнозирование с использованием обученной модели\n",
    "predictions = model.predict(x_new)\n",
    "\n",
    "# Преобразование предсказаний в интерпретируемый вид\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Сопоставление с вашими категориями\n",
    "emotion_mapping = {4: 'sadness', 0: 'anger', 3: 'love', 5: 'surprise', 1: 'fear', 2: 'joy'}\n",
    "predicted_emotions = [emotion_mapping[label] for label in predicted_labels]\n",
    "\n",
    "# Вывод результатов\n",
    "for text, emotion in zip(new_texts, predicted_emotions):\n",
    "    print(f\"Text: {text}, Predicted Emotion: {emotion}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
